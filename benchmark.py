# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bW0OrvsElM89w2WbCQHLFaeFyplNRE3v
"""

import pandas as pd
import matplotlib.pyplot as plt
import pandas as pd
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.seasonal import STL
from scipy import stats
from functools import partial
import numpy as np
# cpdetect has been modified to fit code
from cpdetect.cpdetect import cpDetector
import os
from causalimpact import CausalImpact
import matplotlib.colors as colors
import matplotlib.cm as cmx
#from bfast import BFASTMonitor
from random import seed
from random import gauss
import seaborn as sns
import ruptures as rpt
from ruptures.metrics import hausdorff, randindex, precision_recall

class Benchmark_Models:
  def __init__(self, algo_list):
    self.algo_list = algo_list
    self.result_df = None
    self.signal = None
    self.true_bps = None
  

  def linear_penalty(self, signal, b=0.045):
    return len(signal) * b

  def bic_penalty(self, signal, std=0.08):
    '''BICl2
    '''
    return float(len(signal) * np.log(len(signal)) * (np.std(signal)**2))

  def aic_penalty(self, signal, std=0.08):
    '''AICl2
    '''
    return float(len(signal) * (np.std(signal)**2))

  def extract_climate_trend(self, df, trend='STL'):
    '''
      input_params: 
        df: input the dataframe of which the trends are to be extracted from
            requirements for the dataframe:
            - dataframe index need to be datetime,
            - datetime index should be sorted
            - should be a monthly resampling
    '''
    climate_trend_df = pd.DataFrame()

    if trend == 'STL':
      yr_list = df.index.year
      #print(yr_list[-1])
      #print(yr_list[0])
      seasons = yr_list[-1] - yr_list[0]

      if seasons % 2 == 0:
        seasons += 1
      

      for col in df:
        stl = STL(df[col], period=12, seasonal=seasons, robust=True)
        res = stl.fit()
        #print(res.trend)
        climate_trend_df[col] = res.trend
        
    return climate_trend_df

  def get_decomp_plus_cp(self,signal, dates, decomp_algo='STL', cp_algo='bayes', config=None):
    '''
    task function

    description: applies decomposition, and gets the change points
    '''
    #formatting the np.array to dataframe for trend extraction
    signal = pd.DataFrame({'signal': signal})
    signal.index = dates

    
    #trend extraction
    if config:
      if 'decomp_algo' in config:
        decomp_algo = config['decomp_algo']
    if decomp_algo == 'STL':
      signal_trend = self.extract_climate_trend(signal, 'STL')
      signal = np.array(signal_trend['signal'])

    if decomp_algo == None:
      signal = np.array(signal)

    #change point detection

    #bayesian change point detection
    if cp_algo == 'bayes':
    #change point detection
      
      #assign config if exists
      if config:
        if 'distribution' in config:
          distribution = config['distribution']
        if 'log_odds_threshold' in config:
          log_odds = config['log_odds_threshold']
        detector = cpDetector([signal], distribution=distribution, log_odds_threshold=log_odds)
      #else use log normal and 0 treshold
      else:
        detector = cpDetector([signal], distribution='log_normal', log_odds_threshold=0)
      detector.detect_cp()
      
      
      #gets the breakpoints via idx from the detector
      predicted_breaks = detector.change_points['traj_0']['ts'].values
      predicted_breaks = np.append(predicted_breaks, len(signal))

    if self.pen == 'aic':
        pen = self.aic_penalty(signal)
    elif self.pen == 'bic':
        pen = self.bic_penalty(signal)

    if cp_algo == 'pelt':
      model = 'rbf'
      #pen= 10
      if config:
        if 'model' in config:
          model = config['model']
        if 'pen' in config:
          pen = config['pen']
      algo = rpt.Pelt(model=model).fit(signal)
      #gets the breakpoints via idx from the detector
      predicted_breaks = algo.predict(pen=pen) #may need to change the 10


    if cp_algo == 'binseg':
      algo = rpt.Binseg(model='rbf').fit(signal)
      predicted_breaks = algo.predict(pen=pen)

    if cp_algo == 'window':
      width = 10
      model = 'rbf'
      std = 0.045
      #cost = rpt.costs.CostRank().fit(signal)
      if config:
        if 'width' in config:
          width = config['width']
        if 'model' in config:
          model = config['model']
        if 'std' in config:
          std = config['std']
      n_bkps = 3*len(signal)*std**2

      algo = rpt.Window(width=width).fit(signal)
      predicted_breaks = algo.predict(pen=pen)

    return predicted_breaks



  def run_single_search(self, signal, algo):
    '''
    handler function
    description:
    '''
    

    bp = self.get_decomp_plus_cp(signal, signal.index, cp_algo=algo[0], config=algo[1])
    return bp
    
  


  def get_scores(self, bp, bp_list):
    h_score = hausdorff(bp, bp_list)
    rand_score = randindex(bp, bp_list)
    recall_score = precision_recall(bp, bp_list)

    return (h_score, rand_score, recall_score)

  def run_benchmark(self, signal, real_bps=[], pen='aic'):
    '''
      signal: list
      real_bp: list of idx of breakpoints
    '''
    self.pen = pen
    #initialize the result variables
    f1_score = None
    recall_score = None
    h_score = None
    rand_score = None
    params = None
    ann_err = None
    self.signal = signal
    bps = None
    self.true_bps = real_bps

    self.df = pd.DataFrame({'signal':[signal.values] * len(self.algo_list),
                            'algo': [None] * len(self.algo_list),
                            'f1_score': [f1_score] * len(self.algo_list),
                            'h_score': [h_score] * len(self.algo_list),
                            'randindex': [rand_score] * len(self.algo_list),
                            'ann_err': [ann_err] * len(self.algo_list),
                            'pred_bp': [bps] * len(self.algo_list)
                            }) 

    
    for idx, algo in enumerate(self.algo_list):
      f1_score = None
      recall_score = None
      h_score = None
      rand_score = None
      params = None
      
      #print(algo[0])
      bp = self.run_single_search(signal, algo)
      if type(bp) == np.ndarray:
        #print('check')
        bp = list(bp)
      signal_length = len(signal)
      # if there are breakpoints
      if (type(bp) == list) & (len(bp) > 1):
 
        if len(real_bps) != 0:
            #calculate scores
            h_score, rand_score, recall_score = self.get_scores(bp, real_bps)
    
            if recall_score != (None, None):
              if recall_score[0] != 0 and recall_score[1] != 0: #prevent error zero division error
                f1_score = 2 * (recall_score[0] * recall_score[1]) / (recall_score[0] + recall_score[1])
                
      self.df['f1_score'][idx] = f1_score
      self.df['h_score'][idx] = h_score
      self.df['ann_err'][idx] = len(bp) - len(real_bps)
      self.df['randindex'][idx] = rand_score
      self.df['pred_bp'][idx] = bp
      self.df['algo'][idx] = algo[0]
     

    return self.df

  def get_casual_impacts(self, all_formatted_data_df, only_neg=False, ci_sd_None=False):
    '''
    '''
    out_df = pd.DataFrame({
        'algo': [None] * len(self.df),
        'cp' : [None] * len(self.df),
        'abs_avg_diff' : [None] * len(self.df),
        'rel_avg_diff' : [None] * len(self.df),
        'abs_cum_diff' : [None] * len(self.df),
        'rel_cum_diff' : [None] * len(self.df),
    })
    
    overall_ci_list = []
    
    for row_idx, row in self.df.iterrows():
      out_df.iloc[row_idx]['algo'] = row['algo']
      if row_idx >= 0:
        row_cp_list = []
        row_abs_cum_list = []
        row_rel_cum_list = []
        row_abs_avg_list = []
        row_rel_avg_list = []
        ci_list = []
        
        for cp_idx, cp in enumerate(row['pred_bp']):
          # casual impact first 13 observations were removed due to approximate diffuse initialization
          ci = None
          if cp > 13 and cp != len(self.signal):
            pre_period = [self.signal.index[0], self.signal.index[cp]]
            post_period = [self.signal.index[cp+1], self.signal.index[-1]]

            if ci_sd_None == True:
                ci = CausalImpact(all_formatted_data_df, pre_period, post_period,  nseasons=[{'period':12}], prior_level_sd=None)    
            
            else:
                ci = CausalImpact(all_formatted_data_df, pre_period, post_period,  nseasons=[{'period':12}])
            ci_list.append(ci)
            if only_neg == True:
              if ci.inferences.iloc[-1]['post_cum_y'] - ci.inferences.iloc[-1]['post_cum_pred'] < 0:
                row_cp_list.append(cp)
                
                # absolute mean effect
                abs_mean_eff = self.signal.iloc[cp+1:].mean() - ci.inferences['preds'][cp+1:].mean()
                row_abs_avg_list.append(round(abs_mean_eff,1))

                # relative mean effect
                rel_mean_eff = abs_mean_eff/ci.inferences['preds'][cp+1:].mean() * 100
                row_rel_avg_list.append(round(rel_mean_eff,1))

                # abolute cumalative eff
                abs_cum_eff = ci.inferences['point_effects'][cp+1:].sum()
                row_abs_cum_list.append(round(abs_cum_eff,1))

                #relative cumalative eff
                rel_cum_eff = abs_cum_eff / ci.inferences['preds'][cp+1:].sum() * 100
                row_rel_cum_list.append(round(rel_cum_eff,1))
                
            else:
                row_cp_list.append(cp)
                
                # absolute mean effect
                abs_mean_eff = self.signal.iloc[cp+1:].mean() - ci.inferences['preds'][cp+1:].mean()
                row_abs_avg_list.append(round(abs_mean_eff,1))

                # relative mean effect
                rel_mean_eff = abs_mean_eff/ci.inferences['preds'][cp+1:].mean() * 100
                row_rel_avg_list.append(round(rel_mean_eff,1))

                # abolute cumalative eff
                abs_cum_eff = ci.inferences['point_effects'][cp+1:].sum()
                row_abs_cum_list.append(round(abs_cum_eff,1))

                #relative cumalative eff
                rel_cum_eff = abs_cum_eff / ci.inferences['preds'][cp+1:].sum() * 100
                row_rel_cum_list.append(round(rel_cum_eff,1))
                
        out_df.iloc[row_idx]['cp'] = row_cp_list
        out_df.iloc[row_idx]['abs_avg_diff'] = row_abs_avg_list
        out_df.iloc[row_idx]['rel_avg_diff'] = row_rel_avg_list
        out_df.iloc[row_idx]['abs_cum_diff'] = row_abs_cum_list
        out_df.iloc[row_idx]['rel_cum_diff'] = row_rel_cum_list
        overall_ci_list.append(ci_list)
        
        
    return out_df, overall_ci_list


  def plot(self, selected_cp=None, sig_name='NDVI'):
    '''
    can only plot after running the benchmark
    '''
    if len(self.algo_list) > 1: 
        fig, ax = plt.subplots(len(self.algo_list),1)
    
        for idx, algo in enumerate(self.algo_list):
          ax[idx].plot(self.signal, c='black')
          if selected_cp == None:
            for bp in self.df['pred_bp'][idx][:-1]:
              ax[idx].axvline(self.signal.index[bp], c='r')
          else:
            ax[idx].axvline(self.signal.index[selected_cp], c='r')
          for real_bp in self.true_bps[:-1]:
            ax[idx].axvline(self.signal.index[real_bp], c='dimgray',ls='--')
    
            # draws the left hand side of the graph
            if real_bp - 6 >= 0:
              shaded_left_idx = self.signal.index[real_bp - 6] 
            else:
              shaded_left_idx = self.signal.index[0]
            ax[idx].axvspan(shaded_left_idx,self.signal.index[real_bp], facecolor='silver', alpha=0.5)
    
    
            # draws the right hand side of the graph
            if real_bp + 6 < len(self.signal):
              shaded_right_idx = self.signal.index[real_bp + 6] 
            else:
              shaded_right_idx = self.signal.index[-1]
            ax[idx].axvspan(self.signal.index[real_bp], shaded_right_idx, facecolor='silver', alpha=0.5)
    
          ax[idx].legend((sig_name,'pred cp','drought'))
          ax[idx].set_ylabel(algo[0])
          leg = ax[idx].get_legend()
          leg.legendHandles[0].set_color('black')
          leg.legendHandles[1].set_color('red')
          leg.legendHandles[2].set_color('silver')
    
    else:
        fig, ax = plt.subplots()
        
        algo = self.algo_list[0]
        ax.plot(self.signal, c='black')
        if selected_cp == None:
            for bp in self.df['pred_bp'][0][:-1]:
              ax.axvline(self.signal.index[bp], c='r')
        else:
            ax.axvline(self.signal.index[selected_cp], c='r')
        for real_bp in self.true_bps[:-1]:
            ax.axvline(self.signal.index[real_bp], c='dimgray',ls='--')
    
            # draws the left hand side of the graph
            if real_bp - 6 >= 0:
              shaded_left_idx = self.signal.index[real_bp - 6] 
            else:
              shaded_left_idx = self.signal.index[0]
            ax.axvspan(shaded_left_idx,self.signal.index[real_bp], facecolor='silver', alpha=0.5)
    
    
            # draws the right hand side of the graph
            if real_bp + 6 < len(self.signal):
              shaded_right_idx = self.signal.index[real_bp + 6] 
            else:
              shaded_right_idx = self.signal.index[-1]
            ax.axvspan(self.signal.index[real_bp], shaded_right_idx, facecolor='silver', alpha=0.5)
    
        ax.legend((sig_name,'pred cp','drought'))
        ax.set_ylabel(algo[0])
        leg = ax.get_legend()
        leg.legendHandles[0].set_color('black')
        leg.legendHandles[1].set_color('red')
        leg.legendHandles[2].set_color('silver')