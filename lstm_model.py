# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wcf5bY6W7svUBaSgjmpPfd9eDxWvDxTl
"""

import matplotlib.pyplot as plt
import pandas as pd
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.seasonal import STL
from scipy import stats
from functools import partial
import numpy as np
# cpdetect has been modified to fit code
from cpdetect.cpdetect import cpDetector
import os
from causalimpact import CausalImpact
import matplotlib.colors as colors
import matplotlib.cm as cmx
#from bfast import BFASTMonitor
from random import seed
from random import gauss
import seaborn as sns
import ruptures as rpt
from ruptures.metrics import hausdorff, randindex, precision_recall
from keras.models import load_model
import tensorflow as tf

from keras.models import Sequential
from keras.layers import LSTM
from keras.layers import Dense
from keras.layers import Bidirectional
from keras.callbacks import EarlyStopping
from keras.callbacks import ModelCheckpoint
from keras.models import load_model
from keras.layers import RepeatVector
from keras.layers import TimeDistributed

from sklearn import preprocessing
from sklearn.model_selection import train_test_split

#Supress default INFO logging
import logging, sys
logging.disable(sys.maxsize)

plt.rcParams["figure.figsize"] = (18,6)

import os
os.environ["KERAS_BACKEND"] = "theano"

import warnings
warnings.simplefilter('ignore')
from benchmark import Benchmark_Models
from helper import *
import pandas as pd
from dateutil.relativedelta import relativedelta
import datetime

def make_folder(filename='init_LSTM_model.h5'):

  folder_path = '/model_data/' 
  file_loc = folder_path + filename
  if not os.path.exists(folder_path):
      os.makedirs(folder_path)

  return file_loc



# split a multivariate sequence into samples
def split_sequences(sequences, n_steps_in, n_steps_out):
	X, y = list(), list()
	for i in range(len(sequences)):
		# find the end of this pattern
		end_ix = i + n_steps_in
		out_end_ix = end_ix + n_steps_out
		# check if we are beyond the dataset
		if out_end_ix > len(sequences):
			break
		# gather input and output parts of the pattern
		seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]
		X.append(seq_x)
		y.append(seq_y)
	return np.array(X), np.array(y)

class Forcaster:
  def __init__(self, n_features=8):
    # define model
    self.n_steps_in, self.n_steps_out = 12, 12
    self.n_features = n_features
    self.model = Sequential()
    self.model.add(Bidirectional(LSTM(100, activation='relu', 
                                      input_shape=(self.n_steps_in, self.n_features))))
    self.model.add(RepeatVector(self.n_steps_out))
    self.model.add(Bidirectional(LSTM(100, activation='relu', return_sequences=True)))
    self.model.add(TimeDistributed(Dense(n_features)))
    self.model.compile(optimizer='adam', loss='mse')

  def load_weights(self, weights_loc):
    self.model = load_model(weights_loc)


  def train(self, norm_data):
    # for reproducibility 
    from numpy.random import seed
    seed(1)
    tf.random.set_seed(1)

    dataset = norm_data
    ttl_len = len(dataset)
    train = np.array(dataset.iloc[:int(ttl_len * 0.7)])
    val = np.array(dataset.iloc[int(ttl_len * 0.7):int(ttl_len * 0.8)])
    test = np.array(dataset.iloc[int(ttl_len * 0.8):])

    self.train_X, self.train_y = split_sequences(train, self.n_steps_in, self.n_steps_out)
    self.val_X, self.val_y = split_sequences(val, self.n_steps_in, self.n_steps_out)
    self.test_X, self.test_y = split_sequences(test, self.n_steps_in, self.n_steps_out)

    file_loc = make_folder()
    mc = ModelCheckpoint(file_loc, monitor='val_loss', mode='min', save_best_only=True)
    es = EarlyStopping(monitor='val_loss', mode='min', patience=100)

    self.history = self.model.fit(self.train_X, self.train_y, validation_data=(self.val_X, self.val_y), epochs=1000, verbose=0, callbacks=[es,mc])
    
    self.model = load_model(file_loc)

    return self.model

  def evaluate(self, *args, **kwargs):
    return self.model.evaluate(args, kwargs)

  def predict(self, input_data):
    '''
    args
    -----
    input_data:
      1 year of data before wanted prediction

    output
    -----
    1 year of data
    '''
    cols = input_data.columns
    date_list = []
    
    for x in range(12):
      if x == 0:
        date = input_data.index[-1] + relativedelta(months=1)
      else:
        date = date_list[x-1] + relativedelta(months=1)
      date_list.append(date)


    input_data = np.array(input_data).reshape(1,12,8)

    # for reproducibility 

    from numpy.random import seed
    seed(1)
    tf.random.set_seed(1)

    df = pd.DataFrame(data=self.model.predict(input_data)[0],
                 index=date_list,
                 columns=cols)

    return df